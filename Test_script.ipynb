{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3017266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Random Seed:  9432\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "###################################################################\n",
    "from model_architecture import *\n",
    "from losses import *\n",
    "from Dataloader.Test_Dataloader import *\n",
    "\n",
    "\n",
    "######################## configure device ###############\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# verify that gpu is recognized\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "################## Set random seem for reproducibility ##########\n",
    "manualSeed = 9432\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "\n",
    "########## interactive mode for plots ###################\n",
    "plt.ion()   \n",
    "%matplotlib inline\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14757a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ceb8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Computes Balanced Accuracy ###########\n",
    "def compute_bacc(gt, pred, thresh):\n",
    "    \n",
    "    lst=[]\n",
    "    for t in thresh:\n",
    "        tmp_pred=np.zeros_like(pred)\n",
    "        idx=np.where(pred>t)\n",
    "        tmp_pred[idx]=1\n",
    "        del idx\n",
    "        \n",
    "        tp=np.where((gt==1) & (tmp_pred==1))[0].shape[0]\n",
    "        tn=np.where((gt==0) & (tmp_pred==0))[0].shape[0]\n",
    "        fp=np.where((gt==0) & (tmp_pred==1))[0].shape[0]\n",
    "        fn=np.where((gt==1) & (tmp_pred==0))[0].shape[0]\n",
    "    \n",
    "        sens=tp/(tp+fn)\n",
    "        spec=tn/(tn+fp)\n",
    "        acc=(sens+spec)/2\n",
    "        lst.append(acc)\n",
    "        \n",
    "    lst=np.array(lst)\n",
    "    lst=np.expand_dims(lst, axis=1)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02270e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Compute the AUROC,Concordance Index and Balanced Accuracy ################\n",
    "def compute_performance(indctr_lst, tcnv_lst, risk_scr_lst, pred_lst, gt_lst, thresh):\n",
    "    risk_scr_lst=np.squeeze(risk_scr_lst, axis=1)\n",
    "    \n",
    "    c_index=concordance_index_censored(indctr_lst.astype(bool), tcnv_lst, risk_scr_lst)\n",
    "    c_index=c_index[0]\n",
    "    \n",
    "    auc_lst=[]\n",
    "    b_acc_lst=[]\n",
    "    for cls in range(0,6):\n",
    "        gt=gt_lst[:, cls]\n",
    "        pred=pred_lst[:, cls]\n",
    "        \n",
    "        idx2=np.where(gt !=-1) # -1 implies GT is unavailable (eg. querying for a time-point after censoring has occured)\n",
    "        gt=gt[idx2]\n",
    "        pred=pred[idx2]\n",
    "        \n",
    "        auc_lst.append(roc_auc_score(gt, pred))\n",
    "        b_acc_lst.append(compute_bacc(gt, pred, thresh)) # N,1\n",
    "        del gt, pred, idx2\n",
    "    \n",
    "    auc_lst=np.array(auc_lst)\n",
    "    auc_lst=np.expand_dims(auc_lst, axis=0)    \n",
    "    \n",
    "    b_acc_lst=np.concatenate(b_acc_lst, axis=1) # N,6    \n",
    "    return auc_lst, c_index, b_acc_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0609c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### The inference Code ################\n",
    "def complete_inference(tst_loader):\n",
    "    encoder_model.eval()\n",
    "    classifier_model.eval()\n",
    "    \n",
    "    # time-points at which conversion performance is measured (AUROC and Bal. Accuracy)\n",
    "    t_inp=torch.from_numpy(np.array([6.0, 12.0, 18.0, 24.0, 30.0, 36.0])).to(device) \n",
    "    t_inp=(t_inp/36.0)  # Normalization s.t. 3 year corresponds to 1\n",
    "    \n",
    "    gt_lst=[] # 2D array:  sample, 6 time-points\n",
    "    pred_lst=[]\n",
    "    risk_scr_lst=[]\n",
    "    tcnv_lst=[]\n",
    "    indctr_lst=[]\n",
    "    nm_lst=[]\n",
    "    \n",
    "    for i, sample in enumerate(tst_loader):\n",
    "        img1=sample['img1'].to(device)\n",
    "        img2=sample['img2'].to(device)\n",
    "        img3=sample['img3'].to(device)  # average of 3 images, each containing 3 consecutive B-scans from 3D vol\n",
    "        \n",
    "        gt=sample['gt'] # 6-D  conversion within 6/12/18/24/30/36 month time-points\n",
    "        tcnv=sample['tcnv']\n",
    "        indctr=sample['indctr']\n",
    "        nm=sample['nm']\n",
    "        nm=np.array(nm)\n",
    "        \n",
    "        img1=rearrange(img1, 'b 1 c h w -> b c h w')\n",
    "        img2=rearrange(img2, 'b 1 c h w -> b c h w')\n",
    "        img3=rearrange(img3, 'b 1 c h w -> b c h w')\n",
    "        \n",
    "        \n",
    "        ### Forward Pass\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            ftr1=encoder_model(img1)\n",
    "            ftr2=encoder_model(img2)\n",
    "            ftr3=encoder_model(img3)\n",
    "            \n",
    "            tmp=t_inp.unsqueeze(dim=0).repeat(img1.shape[0],1).to(dtype=torch.float32)\n",
    "            rsk_curr1, pred_logits1=classifier_model(ftr1, tmp) # 3B, 1  and 3B,1\n",
    "            rsk_curr2, pred_logits2=classifier_model(ftr2, tmp) # 3B, 1  and 3B,1\n",
    "            rsk_curr3, pred_logits3=classifier_model(ftr3, tmp) # 3B, 1  and 3B,1\n",
    "            \n",
    "            p1=F.sigmoid(pred_logits1)\n",
    "            p2=F.sigmoid(pred_logits2)\n",
    "            p3=F.sigmoid(pred_logits3)\n",
    "            del tmp \n",
    "                \n",
    "        p1=p1.detach().cpu().numpy()\n",
    "        p2=p2.detach().cpu().numpy()\n",
    "        p3=p3.detach().cpu().numpy()\n",
    "        \n",
    "        rsk_curr1=rsk_curr1.detach().cpu().numpy()\n",
    "        rsk_curr2=rsk_curr2.detach().cpu().numpy()\n",
    "        rsk_curr3=rsk_curr3.detach().cpu().numpy()\n",
    "        \n",
    "        p=(p1+p2+p3)/3.0\n",
    "        rsk_curr=(rsk_curr1+rsk_curr2+rsk_curr3)/3.0\n",
    "        ################################################\n",
    "        \n",
    "        pred_lst.append(p)\n",
    "        risk_scr_lst.append(rsk_curr) # risk predicted for the current input scan\n",
    "        nm_lst.append(nm)\n",
    "        gt_lst.append(gt)\n",
    "        tcnv_lst.append(tcnv)\n",
    "        indctr_lst.append(indctr)\n",
    "        \n",
    "        del img1, img2, img3, gt, tcnv, indctr, nm, ftr1, ftr2, ftr3, \n",
    "        del rsk_curr1, rsk_curr2, rsk_curr3\n",
    "        del p1, p2, p3, p, rsk_curr\n",
    "    \n",
    "    \n",
    "    \n",
    "    pred_lst=np.concatenate(pred_lst, axis=0) # or stack?  # B,6\n",
    "    risk_scr_lst=np.concatenate(risk_scr_lst, axis=0)      # B,1\n",
    "    nm_lst=np.concatenate(nm_lst, axis=0)                  # B,\n",
    "    gt_lst=np.concatenate(gt_lst, axis=0)                  # B,6\n",
    "    tcnv_lst=np.concatenate(tcnv_lst, axis=0)              # B,\n",
    "    indctr_lst=np.concatenate(indctr_lst, axis=0)          # B,\n",
    "    \n",
    "    \n",
    "    ### Sort the list which is used to define the index for the samples of each bootstrap re-sampling.\n",
    "    idx=np.argsort(nm_lst, axis=0)\n",
    "    pred_lst=pred_lst[idx,:]           # B,6\n",
    "    risk_scr_lst=risk_scr_lst[idx,:]   # B,1\n",
    "    nm_lst=nm_lst[idx]                 # B,\n",
    "    gt_lst=gt_lst[idx,:]               # B,6\n",
    "    tcnv_lst=tcnv_lst[idx]             # B,\n",
    "    indctr_lst=indctr_lst[idx]         # B,\n",
    "    del idx\n",
    "    \n",
    "    ### Check that the sorted nm_lst is same as the validation dataloader\n",
    "    ## This ordering is required to compute the boot-strap performance at the eye-level. \n",
    "    flag=np.array_equal(nm_lst, tst_data.nm_lst) # this is the order used to define bootstrap samplings\n",
    "    if flag==False:\n",
    "        print('the nm_lst doesnot match !')\n",
    "        \n",
    "    ####### save the predictions   ##############\n",
    "    np.savez('save_predictions.npz', pred_lst=pred_lst, risk_scr_lst=risk_scr_lst, nm_lst=nm_lst,\n",
    "             gt_lst=gt_lst, tcnv_lst=tcnv_lst, indctr_lst=indctr_lst, indices=tst_data.sampling_index)\n",
    "    \n",
    "    \n",
    "    ##### Compute the scan-level performance ####\n",
    "    thresh=np.sort(np.unique(pred_lst.flatten()))\n",
    "    scn_lvl_auc, scn_lvl_ci, scn_lvl_bacc=compute_performance(indctr_lst, tcnv_lst, risk_scr_lst, pred_lst, gt_lst, thresh)\n",
    "    scn_lvl_bacc=np.max(scn_lvl_bacc, axis=0)   \n",
    "    \n",
    "    ###### Now everything is sorted by name. So now, we can use the pre-saved indices ###\n",
    "    # In Each bootstrap only scan from 1 visit per eye is randomly selected. Performance is averaged across 1000 bootstrap re-samplings\n",
    "    # The indices of the scans used in each bootstrap are pre-saved inside tst_data.sampling_index to ensure same bootstrap samplings are used for different methods.\n",
    "    indices=tst_data.sampling_index\n",
    "    c_lst=[]\n",
    "    auc_lst=[]\n",
    "    bacc_lst=[]\n",
    "    ############ The following part would take some time as it computes performance for 1000 different samplings\n",
    "    for k in range(0, len(indices)): # No. of bootstrap re-samplings \n",
    "        if (k % 100)==0:\n",
    "            print(k)\n",
    "        \n",
    "        idx=indices[k]  # contains indices of which scans are in the current bootstrap sampling\n",
    "        tmp_rsk=risk_scr_lst[idx,:] # B,1\n",
    "        tmp_tcnv=tcnv_lst[idx]\n",
    "        tmp_indctr=indctr_lst[idx]\n",
    "        tmp_gt=gt_lst[idx,:]\n",
    "        tmp_pred=pred_lst[idx,:]\n",
    "        \n",
    "        tmp_auc, tmp_ci, tmp_bacc=compute_performance(tmp_indctr, tmp_tcnv, tmp_rsk, tmp_pred, tmp_gt, thresh)\n",
    "        # tmp_auc, tmp_ci are scalar values.     tmp_bacc: N,6\n",
    "        \n",
    "        auc_lst.append(tmp_auc)\n",
    "        c_lst.append(tmp_ci)\n",
    "        bacc_lst.append(tmp_bacc)\n",
    "        del idx, tmp_rsk, tmp_tcnv, tmp_indctr, tmp_gt, tmp_pred, tmp_auc, tmp_ci, tmp_bacc\n",
    "        \n",
    "    \n",
    "    auc_lst=np.concatenate(auc_lst, axis=0)   # 1000,6\n",
    "    c_lst=np.array(c_lst)                     # 1000,6\n",
    "    bacc_lst=np.stack(bacc_lst, axis=0)       # 1000,N,6\n",
    "    \n",
    "    tmp=np.mean(bacc_lst, axis=0) # N,6\n",
    "    print('thresholds Scan Level: ')\n",
    "    idx0=np.argmax(tmp[:,0])\n",
    "    idx1=np.argmax(tmp[:,1])\n",
    "    idx2=np.argmax(tmp[:,2])\n",
    "    idx3=np.argmax(tmp[:,3])\n",
    "    idx4=np.argmax(tmp[:,4])\n",
    "    idx5=np.argmax(tmp[:,5])\n",
    "    \n",
    "    bacc_lst=np.concatenate([bacc_lst[:,idx0,0:1], bacc_lst[:,idx1,1:2], bacc_lst[:,idx2,2:3], bacc_lst[:,idx3,3:4],\n",
    "              bacc_lst[:,idx4,4:5], bacc_lst[:,idx5,5:6]], axis=1)\n",
    "    print('bacc_lst: '+str(bacc_lst.shape))\n",
    "    del tmp, idx0, idx1, idx2, idx3, idx4, idx5\n",
    "    \n",
    "    ######## Save the metrics #######\n",
    "    np.savez('performance.npz', scn_lvl_auc=scn_lvl_auc, scn_lvl_ci=scn_lvl_ci, scn_lvl_bacc=scn_lvl_bacc,\n",
    "             bootstrp_auc=auc_lst, bootstrp_ci=c_lst, bootstrp_bacc=bacc_lst)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4678ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fd5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7671b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1887\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "thresholds Scan Level: \n",
      "bacc_lst: (1000, 6)\n"
     ]
    }
   ],
   "source": [
    "############### Data Loader #######################################\n",
    "\n",
    "tst_data=test_dataset()\n",
    "tst_loader=DataLoader(dataset=tst_data, batch_size=16, shuffle=False, num_workers=2, \n",
    "                             pin_memory=False, drop_last=False, worker_init_fn=worker_init_fn)\n",
    "\n",
    "\n",
    "\n",
    "################## Prepare the model  ############################### \n",
    "encoder_model=Encoder_Network2D()\n",
    "classifier_model=Classification_Network()\n",
    "\n",
    "encoder_model.to(device)\n",
    "classifier_model.to(device)\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "# Load weights\n",
    "checkpoint=torch.load('src_weight_fld5_metric1.4942585858396749.pt')\n",
    "encoder_model.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "classifier_model.load_state_dict(checkpoint['classifier_state_dict'])\n",
    "del checkpoint\n",
    "\n",
    "# test mode\n",
    "encoder_model.eval()\n",
    "classifier_model.eval()\n",
    "\n",
    "\n",
    "complete_inference(tst_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
